{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq \n",
    "load_dotenv()\n",
    "api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "cohere_api_key = os.environ.get(\"COHERE_API_KEY\")\n",
    "serpapi_api_key = os.environ.get(\"SERP_API_KEY\")\n",
    "llm = ChatGroq(temperature=0.8, model=\"llama-3.3-70b-specdec\", api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file_path = \"2304.00501v6.pdf\" \n",
    "PAPERS_DIR = \"Papers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from datetime import datetime\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "loader = DirectoryLoader(PAPERS_DIR, glob=\"**/*.pdf\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=500)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = Chroma.from_documents(documents=chunks, embedding=embeddings,persist_directory=\"chromdb\")\n",
    "retriever = db.as_retriever(k=min(len(db), 10))\n",
    "def generate_rfq_with_details(llm,query):\n",
    "    try:\n",
    "        prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        Answer the following question based only on the provided context.\n",
    "        Think step by step before providing a detailed answer.\n",
    "        <context>\n",
    "        {context}\n",
    "        <context>\n",
    "        Question: {input}\n",
    "        \"\"\")\n",
    "        chain = create_stuff_documents_chain(llm=llm,prompt=prompt)\n",
    "        retriver_chain = create_retrieval_chain(retriever,chain)\n",
    "        answer = retriver_chain.invoke({\"input\" : query})\n",
    "        return answer[\"answer\"]\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, Attention refers to a mechanism used in the Transformer model, specifically in the encoder-decoder attention layers and self-attention layers. It allows the model to focus on different parts of the input sequence when generating output, by attending to specific positions in the input sequence.\\n\\nIn the context, Attention is described as a way for the model to:\\n\\n1. Follow long-distance dependencies in the input sequence (Figure 3)\\n2. Resolve anaphora (Figure 4)\\n3. Attend to different positions in the input sequence (Section 3.2.3)\\n\\nThe Attention mechanism is implemented using multi-head attention, where different attention heads learn to perform different tasks, such as attending to specific words or phrases in the input sequence.\\n\\nIn general, Attention can be understood as a way for the model to selectively focus on certain parts of the input sequence, rather than considering the entire sequence equally, in order to generate more accurate and relevant output.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_rfq_with_details(llm,\"What is Attention ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
